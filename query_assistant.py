# interactive_assistant.py (äº¤äº’å¼ Ollama API è°ƒç”¨)
import os
import requests
import json
from typing import List, Dict, Optional
from chromadb import PersistentClient
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction

# ========================
# é…ç½®åŒº
# ========================
CHROMA_PATH = "E:/code/studentRAG/chroma_db_advanced"  # å‘é‡åº“å­˜å‚¨è·¯å¾„
OLLAMA_MODEL = "qwen3:14b"                            # æœ¬åœ° Ollama æ¨¡å‹åç§°
OLLAMA_URL = "http://localhost:11434/api/generate"    # Ollama API URL
EMBEDDING_MODEL = "BAAI/bge-large-zh-v1.5"             
TOP_K = 5                                             # å¬å›ç‰‡æ®µæ•°é‡

# ========================
# Prompt Template (æç¤ºè¯å·¥ç¨‹ï¼šä¿æŒä¸å˜ï¼Œç”¨äºå†…å®¹å¡«å……)
# ========================
RAG_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€ä¸¥è°¨çš„å¤§å­¦å­¦ç”Ÿæ™ºèƒ½åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„**ä¸Šä¸‹æ–‡èµ„æ–™**ï¼Œå‡†ç¡®ã€ç®€æ´åœ°å›ç­”å­¦ç”Ÿçš„æé—®ã€‚

è¯·éµå®ˆä»¥ä¸‹ä¸¥æ ¼çš„çº¦æŸå’Œæ­¥éª¤ï¼š
1.  **ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡ï¼š** ä½ çš„å›ç­”å¿…é¡»ä¸”ä»…åŸºäºã€ä¸Šä¸‹æ–‡èµ„æ–™ã€‘ä¸­æä¾›çš„ä¿¡æ¯ã€‚
2.  **æå–å¹¶å¼•ç”¨ï¼š** åœ¨å›ç­”ä¸­ï¼Œç”¨ä¸­æ–‡åˆ†ç‚¹åˆ—å‡ºå…³é”®ä¿¡æ¯ã€‚
3.  **æ³¨æ˜æ¥æºï¼š** åœ¨å›ç­”çš„æœ€åï¼ŒåŠ¡å¿…ä»¥â€œèµ„æ–™æ¥æºï¼š[æ–‡ä»¶å]â€çš„æ ¼å¼ï¼Œæ³¨æ˜ä½ ä½¿ç”¨çš„æ‰€æœ‰ä¸Šä¸‹æ–‡èµ„æ–™çš„æ–‡ä»¶åï¼ˆæ¥è‡ªä¸Šä¸‹æ–‡ä¸­çš„ 'source'ï¼‰ã€‚
4.  **æ— æ³•å›ç­”æ—¶ï¼š** å¦‚æœä¸Šä¸‹æ–‡èµ„æ–™æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·ç¤¼è²Œåœ°å›ç­”ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»ç°æœ‰çš„å­¦ç”Ÿæ‰‹å†Œèµ„æ–™ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚â€

---
ã€ä¸Šä¸‹æ–‡èµ„æ–™ã€‘
{context}
---
ã€å­¦ç”Ÿé—®é¢˜ã€‘
{question}
"""

# ========================
# åˆå§‹åŒ–å‡½æ•° (ä¿æŒä¸å˜)
# ========================
def initialize_rag_system():
    """åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å’Œ Embedding Function"""
    print(f"ğŸ”„ åˆå§‹åŒ– RAG ç³»ç»Ÿ...")
    
    # 1. åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯
    client = PersistentClient(path=CHROMA_PATH)
    
    # 2. åˆå§‹åŒ– Embedding Function
    embedding_func = SentenceTransformerEmbeddingFunction(
        model_name=EMBEDDING_MODEL,
        device="cuda" if _is_cuda_available() else "cpu"
    )
    
    # 3. è·å– Collection
    collection = client.get_collection(
        name="student_handbook_advanced",
        embedding_function=embedding_func
    )
    
    print(f"âœ… RAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚å½“å‰å‘é‡åº“ç‰‡æ®µæ•°: {collection.count()}")
    return collection

def _is_cuda_available():
    try:
        import torch
        return torch.cuda.is_available()
    except ImportError:
        return False

# ========================
# Ollama API è°ƒç”¨å‡½æ•° (æ ¸å¿ƒä¿®æ”¹ç‚¹)
# ========================
def generate_response_ollama_api(prompt: str) -> str:
    """ä½¿ç”¨ requests åº“è°ƒç”¨ Ollama çš„ /api/generate æ¥å£"""
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,  # è®¾ç½®ä¸º False ä»¥ä¾¿ä¸€æ¬¡æ€§è·å–å®Œæ•´å›å¤
        "options": {
            "temperature": 0.1, # ä¿æŒä½æ¸©åº¦
            "num_predict": 1024 # é™åˆ¶æœ€å¤§è¾“å‡º token æ•°
        }
    }
    
    try:
        # å‘é€ POST è¯·æ±‚åˆ° Ollama API
        response = requests.post(OLLAMA_URL, json=payload)
        response.raise_for_status() # æ£€æŸ¥ HTTP é”™è¯¯
        
        # è§£æå“åº”
        data = response.json()
        return data.get('response', 'Ollama è¿”å›ä¸ºç©ºã€‚')
        
    except requests.exceptions.RequestException as e:
        return f"âŒ Ollama API è°ƒç”¨å¤±è´¥ï¼šè¯·æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œã€‚é”™è¯¯: {e}"
    except json.JSONDecodeError:
        return f"âŒ Ollama API è¿”å›æ ¼å¼é”™è¯¯ã€‚"

# ========================
# RAG æŸ¥è¯¢ä¸»å‡½æ•° (è°ƒæ•´è¿‡æ»¤é€»è¾‘)
# ========================
def rag_query(collection, query: str, handbook_type: Optional[str] = None):
    """
    æ‰§è¡Œ RAG æŸ¥è¯¢ï¼Œæ”¯æŒå…ƒæ•°æ®è¿‡æ»¤
    :param collection: ChromaDB Collection å¯¹è±¡
    :param query: ç”¨æˆ·çš„æŸ¥è¯¢å­—ç¬¦ä¸²
    :param handbook_type: å¯é€‰ï¼Œç”¨äºè¿‡æ»¤çš„æ‰‹å†Œç±»å‹ ('æœ¬ç§‘ç”Ÿ', 'ç ”ç©¶ç”Ÿ')
    """
    
    # 1. è®¾ç½®å…ƒæ•°æ®è¿‡æ»¤ (where å­å¥)
    where_filter = None  # é»˜è®¤è®¾ç½®ä¸º None (è¡¨ç¤ºä¸è¿›è¡Œè¿‡æ»¤)
    
    if handbook_type:
        # ã€ä¿®æ”¹ 1ï¼šä½¿ç”¨ ChromaDB è¦æ±‚çš„ $eq æ“ä½œç¬¦ã€‘
        where_filter = {
            "handbook_type": {
                "$eq": handbook_type
            }
        }
        print(f"ğŸ” ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤: ä»…æœç´¢ã€{handbook_type}ã€‘æ‰‹å†Œã€‚")

    # 2. å¬å› (Retrieval)
    # print(f"ğŸ” æ­£åœ¨ä»å‘é‡åº“å¬å› Top {TOP_K} ç›¸å…³çš„ç‰‡æ®µ...")
    try:
        results = collection.query(
            query_texts=[query],
            n_results=TOP_K,
            where=where_filter,  # ã€ä¿®æ”¹ 2ï¼šå¦‚æœ where_filter æ˜¯ Noneï¼ŒChromaDB ä¼šè·³è¿‡è¿‡æ»¤ã€‘
            include=['documents', 'metadatas']
        )
    except Exception as e:
        print(f"âŒ å‘é‡åº“æŸ¥è¯¢å¤±è´¥ï¼è¯¦ç»†é”™è¯¯: {e}") 
        return "RAG ç³»ç»Ÿé”™è¯¯ï¼šå‘é‡åº“æŸ¥è¯¢å¤±è´¥ã€‚"

    # æå–ä¸Šä¸‹æ–‡ (åç»­ä»£ç ä¸å˜)
    context_list = results.get('documents', [[]])[0]
    metadata_list = results.get('metadatas', [[]])[0]
    
    if not context_list:
        return f"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»ç°æœ‰çš„æ‰‹å†Œèµ„æ–™ä¸­æ‰¾åˆ°ä¸é—®é¢˜ â€œ{query}â€ ç›¸å…³çš„ä¿¡æ¯ã€‚"

    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡å’Œæ¥æºä¿¡æ¯
    context_str = ""
    for i, (doc, meta) in enumerate(zip(context_list, metadata_list)):
        source_name = meta.get('source', 'æœªçŸ¥æ¥æº')
        handbook_type_name = meta.get('handbook_type', 'æœªçŸ¥ç±»å‹')
        context_str += f"--- ç‰‡æ®µ {i+1} (æ¥æº: {source_name}, ç±»å‹: {handbook_type_name}) ---\n"
        context_str += doc + "\n"
    
    # 3. æ„é€ æœ€ç»ˆ Prompt
    final_prompt = RAG_PROMPT_TEMPLATE.format(
        context=context_str,
        question=query
    )
    
    # 4. ç”Ÿæˆ (Generation) - è°ƒç”¨ Ollama API
    response_content = generate_response_ollama_api(final_prompt)
    return response_content

# ========================
# ä¸»ç¨‹åºå…¥å£ï¼šäº¤äº’å¼å¯¹è¯
# ========================
if __name__ == "__main__":
    collection = initialize_rag_system()
    
    print("\n" + "="*50)
    print(f"ğŸš€ æ™ºèƒ½å­¦ç”ŸåŠ©æ‰‹å·²å¯åŠ¨ (æ¨¡å‹: {OLLAMA_MODEL})")
    print("æç¤ºï¼šè¾“å…¥ 'æœ¬ç§‘ç”Ÿ' æˆ– 'ç ”ç©¶ç”Ÿ' åˆ‡æ¢æœç´¢èŒƒå›´ï¼Œè¾“å…¥ 'quit' é€€å‡ºã€‚")
    print("="*50)

    current_filter = None
    
    while True:
        # 1. è·å–ç”¨æˆ·è¾“å…¥
        user_input = input(f"\n[{current_filter or 'é€šç”¨'}] ä½ æƒ³é—®ï¼š").strip()
        
        # 2. å¤„ç†é€€å‡ºæŒ‡ä»¤
        if user_input.lower() == 'quit':
            print("ğŸ‘‹ åŠ©æ‰‹å·²å…³é—­ã€‚")
            break
        
        # 3. å¤„ç†è¿‡æ»¤æŒ‡ä»¤ (å…ƒæ•°æ®åˆ‡æ¢)
        elif user_input in ["æœ¬ç§‘ç”Ÿ", "ç ”ç©¶ç”Ÿ"]:
            current_filter = user_input
            print(f"âœ… æœç´¢èŒƒå›´å·²åˆ‡æ¢ä¸ºï¼šã€{current_filter}ã€‘æ‰‹å†Œã€‚")
            continue
        
        # 4. æ‰§è¡Œ RAG æŸ¥è¯¢
        if not user_input:
            continue

        print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
        
        result = rag_query(
            collection, 
            query=user_input, 
            handbook_type=current_filter
        )
        
        # 5. è¾“å‡ºç»“æœ
        print("\n" + "--- æ™ºèƒ½åŠ©æ‰‹å›ç­” ---")
        print(result)
        print("----------------------")