# interactive_assistant.py (é›†æˆ Query Rewriting)
import os
import requests
import json
from typing import List, Dict, Optional
from chromadb import PersistentClient
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction

# ========================
# é…ç½®åŒº
# ========================
CHROMA_PATH = "E:/code/studentRAG/chroma_db_advanced"  # å‘é‡åº“å­˜å‚¨è·¯å¾„
OLLAMA_MODEL = "qwen3:14b"                            # æœ¬åœ° Ollama æ¨¡å‹åç§°
OLLAMA_URL = "http://localhost:11434/api/generate"    # Ollama API URL
EMBEDDING_MODEL = "BAAI/bge-large-zh-v1.5"             
TOP_K = 5                                             # å¬å›ç‰‡æ®µæ•°é‡

# ========================
# Prompt Template
# ========================

# 1. å¬å›å¢å¼ºï¼šæŸ¥è¯¢é‡å†™æç¤ºè¯
QUERY_REWRITE_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„RAGç³»ç»ŸæŸ¥è¯¢é‡å†™å™¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·å£è¯­åŒ–ã€æ¨¡ç³Šæˆ–ä¸å®Œæ•´çš„æé—®ï¼Œæ”¹å†™æˆä¸€ä¸ªæˆ–å¤šä¸ª(ä¸è¶…è¿‡3ä¸ª)ï¼Œæ›´æ­£å¼ã€æ›´ä¸“ä¸šçš„ã€æ›´å¯èƒ½å‘½ä¸­å¤§å­¦å­¦ç”Ÿæ‰‹å†Œä¸­æ ‡å‡†æ¡æ¬¾æˆ–æ ‡é¢˜çš„æœç´¢æŸ¥è¯¢ã€‚

ä»…è¾“å‡ºæ”¹å†™åçš„æŸ¥è¯¢ï¼Œæ— éœ€ä»»ä½•è§£é‡Šæˆ–å‰ç¼€ã€‚

ã€åŸå§‹é—®é¢˜ã€‘ï¼š{query}
ã€æ”¹å†™åçš„ä¸“ä¸šæŸ¥è¯¢ã€‘ï¼š
"""

# 2. æœ€ç»ˆç”Ÿæˆï¼šRAG æç¤ºè¯
RAG_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€ä¸¥è°¨çš„å¤§å­¦å­¦ç”Ÿæ™ºèƒ½åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„**ä¸Šä¸‹æ–‡èµ„æ–™**ï¼Œå‡†ç¡®ã€ç®€æ´åœ°å›ç­”å­¦ç”Ÿçš„æé—®ã€‚

è¯·éµå®ˆä»¥ä¸‹ä¸¥æ ¼çš„çº¦æŸå’Œæ­¥éª¤ï¼š
1.  **ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡ï¼š** ä½ çš„å›ç­”å¿…é¡»ä¸”ä»…åŸºäºã€ä¸Šä¸‹æ–‡èµ„æ–™ã€‘ä¸­æä¾›çš„ä¿¡æ¯ã€‚
2.  **æå–å¹¶å¼•ç”¨ï¼š** åœ¨å›ç­”ä¸­ï¼Œç”¨ä¸­æ–‡åˆ†ç‚¹åˆ—å‡ºå…³é”®ä¿¡æ¯ã€‚
3.  **æ³¨æ˜æ¥æºï¼š** åœ¨å›ç­”çš„æœ€åï¼ŒåŠ¡å¿…ä»¥â€œèµ„æ–™æ¥æºï¼š[æ–‡ä»¶å]â€çš„æ ¼å¼ï¼Œæ³¨æ˜ä½ ä½¿ç”¨çš„æ‰€æœ‰ä¸Šä¸‹æ–‡èµ„æ–™çš„æ–‡ä»¶åï¼ˆæ¥è‡ªä¸Šä¸‹æ–‡ä¸­çš„ 'source'ï¼‰ã€‚
4.  **æ— æ³•å›ç­”æ—¶ï¼š** å¦‚æœä¸Šä¸‹æ–‡èµ„æ–™æ— æ³•å›ç­”é—®é¢˜ï¼Œè¯·ç¤¼è²Œåœ°å›ç­”ï¼šâ€œæŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»ç°æœ‰çš„å­¦ç”Ÿæ‰‹å†Œèµ„æ–™ä¸­æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚â€

---
ã€ä¸Šä¸‹æ–‡èµ„æ–™ã€‘
{context}
---
ã€å­¦ç”Ÿé—®é¢˜ã€‘
{question}
"""

# ========================
# è¾…åŠ©å‡½æ•°
# ========================
def _is_cuda_available():
    try:
        import torch
        return torch.cuda.is_available()
    except ImportError:
        return False

def initialize_rag_system():
    """åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å’Œ Embedding Function"""
    print(f"ğŸ”„ åˆå§‹åŒ– RAG ç³»ç»Ÿ...")
    client = PersistentClient(path=CHROMA_PATH)
    embedding_func = SentenceTransformerEmbeddingFunction(
        model_name=EMBEDDING_MODEL,
        device="cuda" if _is_cuda_available() else "cpu"
    )
    collection = client.get_collection(
        name="student_handbook_advanced",
        embedding_function=embedding_func
    )
    print(f"âœ… RAG ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆã€‚å½“å‰å‘é‡åº“ç‰‡æ®µæ•°: {collection.count()}")
    return collection

def generate_response_ollama_api(prompt: str) -> str:
    """ä½¿ç”¨ requests åº“è°ƒç”¨ Ollama çš„ /api/generate æ¥å£"""
    payload = {
        "model": OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.1, 
            "num_predict": 1024 
        }
    }
    
    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=300) # å¢åŠ  timeout
        response.raise_for_status() 
        data = response.json()
        return data.get('response', 'Ollama è¿”å›ä¸ºç©ºã€‚')
        
    except requests.exceptions.RequestException as e:
        return f"âŒ Ollama API è°ƒç”¨å¤±è´¥ï¼šè¯·æ£€æŸ¥ Ollama æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œã€‚é”™è¯¯: {e}"
    except json.JSONDecodeError:
        return f"âŒ Ollama API è¿”å›æ ¼å¼é”™è¯¯ã€‚"

# ========================
# ã€æ–°å¢ã€‘æŸ¥è¯¢è½¬æ¢å‡½æ•°
# ========================
def rewrite_query(query: str) -> str:
    """å°†ç”¨æˆ·æŸ¥è¯¢è½¬æ¢ä¸ºæ›´ä¸“ä¸šçš„æœç´¢è¯"""
    rewrite_prompt = QUERY_REWRITE_PROMPT.format(query=query)
    
    # ä½¿ç”¨ Ollama API è¿›è¡Œæ”¹å†™
    # æ³¨æ„ï¼šæˆ‘ä»¬ä½¿ç”¨ temperature=0.1 ä¿æŒæ”¹å†™ç»“æœçš„ç¨³å®šæ€§
    rewritten_query = generate_response_ollama_api(rewrite_prompt)
    
    # æ¸…ç†å¹¶è¿”å›ç¬¬ä¸€ä¸ªæ”¹å†™ç»“æœï¼ˆå¦‚æœæ¨¡å‹è¾“å‡ºäº†å¤šä¸ªï¼Œåªå–ç¬¬ä¸€è¡Œï¼‰
    rewritten_query = rewritten_query.strip().split('\n')[0].replace('ã€æ”¹å†™åçš„ä¸“ä¸šæŸ¥è¯¢ã€‘ï¼š', '').strip()
    
    # é¿å…ç©ºæŸ¥è¯¢ï¼Œå¦‚æœæ”¹å†™å¤±è´¥ï¼Œä»ä½¿ç”¨åŸæŸ¥è¯¢
    if not rewritten_query or rewritten_query.lower() == 'ollama è¿”å›ä¸ºç©ºã€‚':
        return query
    
    return rewritten_query

# ========================
# RAG æŸ¥è¯¢ä¸»å‡½æ•° (è°ƒæ•´ï¼šåŠ å…¥æŸ¥è¯¢è½¬æ¢)
# ========================
def rag_query(collection, query: str, handbook_type: Optional[str] = None):
    """
    æ‰§è¡Œ RAG æŸ¥è¯¢ï¼Œå…ˆè¿›è¡ŒæŸ¥è¯¢è½¬æ¢ï¼Œå†å¬å›ã€‚
    """
    
    # 0. ã€æ–°æ­¥éª¤ã€‘æ‰§è¡ŒæŸ¥è¯¢è½¬æ¢
    rewritten_query = rewrite_query(query)
    
    if rewritten_query != query:
        print(f"  âœ¨ æŸ¥è¯¢å·²æ”¹å†™ï¼š'{query}' -> '{rewritten_query}'")
    else:
        print(f"  â¡ï¸ ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼š'{query}'")
    
    # 1. è®¾ç½®å…ƒæ•°æ®è¿‡æ»¤ (where å­å¥)
    where_filter = None 
    if handbook_type:
        where_filter = {"handbook_type": {"$eq": handbook_type}}
        print(f"ğŸ” ä½¿ç”¨å…ƒæ•°æ®è¿‡æ»¤: ä»…æœç´¢ã€{handbook_type}ã€‘æ‰‹å†Œã€‚")

    # 2. å¬å› (Retrieval) - **ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢**
    try:
        results = collection.query(
            query_texts=[rewritten_query], # <--- ä½¿ç”¨æ”¹å†™åçš„æŸ¥è¯¢
            n_results=TOP_K,
            where=where_filter,
            include=['documents', 'metadatas']
        )
    except Exception as e:
        print(f"âŒ å‘é‡åº“æŸ¥è¯¢å¤±è´¥ï¼è¯¦ç»†é”™è¯¯: {e}") 
        return "RAG ç³»ç»Ÿé”™è¯¯ï¼šå‘é‡åº“æŸ¥è¯¢å¤±è´¥ã€‚"

    # æå–ä¸Šä¸‹æ–‡ (åç»­ä»£ç ä¿æŒä¸å˜)
    context_list = results.get('documents', [[]])[0]
    metadata_list = results.get('metadatas', [[]])[0]
    
    if not context_list:
        return f"æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ä»ç°æœ‰çš„æ‰‹å†Œèµ„æ–™ä¸­æ‰¾åˆ°ä¸é—®é¢˜ â€œ{query}â€ ç›¸å…³çš„ä¿¡æ¯ã€‚"

    # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡å’Œæ¥æºä¿¡æ¯
    context_str = ""
    for i, (doc, meta) in enumerate(zip(context_list, metadata_list)):
        source_name = meta.get('source', 'æœªçŸ¥æ¥æº')
        handbook_type_name = meta.get('handbook_type', 'æœªçŸ¥ç±»å‹')
        context_str += f"--- ç‰‡æ®µ {i+1} (æ¥æº: {source_name}, ç±»å‹: {handbook_type_name}) ---\n"
        context_str += doc + "\n"
    
    # 3. æ„é€ æœ€ç»ˆ Prompt - **ä½¿ç”¨åŸå§‹æŸ¥è¯¢**
    final_prompt = RAG_PROMPT_TEMPLATE.format(
        context=context_str,
        question=query # <--- æœ€ç»ˆå›ç­”æ—¶ï¼Œä¾ç„¶ä½¿ç”¨åŸå§‹æŸ¥è¯¢ï¼Œç¡®ä¿ç­”æ¡ˆç¬¦åˆç”¨æˆ·è¯­å¢ƒ
    )
    
    # 4. ç”Ÿæˆ (Generation)
    response_content = generate_response_ollama_api(final_prompt)
    return response_content


# ========================
# ä¸»ç¨‹åºå…¥å£ï¼šäº¤äº’å¼å¯¹è¯ (ä¿æŒä¸å˜)
# ========================
if __name__ == "__main__":
    collection = initialize_rag_system()
    
    print("\n" + "="*50)
    print(f"ğŸš€ æ™ºèƒ½å­¦ç”ŸåŠ©æ‰‹å·²å¯åŠ¨ (æ¨¡å‹: {OLLAMA_MODEL})")
    print("æç¤ºï¼šè¾“å…¥ 'æœ¬ç§‘ç”Ÿ' æˆ– 'ç ”ç©¶ç”Ÿ' åˆ‡æ¢æœç´¢èŒƒå›´ï¼Œè¾“å…¥ 'quit' é€€å‡ºã€‚")
    print("ã€å·²å¯ç”¨æŸ¥è¯¢è½¬æ¢ (Query Rewriting) å¢å¼ºå¬å›ã€‘")
    print("="*50)

    current_filter = None
    
    while True:
        user_input = input(f"\n[{current_filter or 'é€šç”¨'}] ä½ æƒ³é—®ï¼š").strip()
        
        if user_input.lower() == 'quit':
            print("ğŸ‘‹ åŠ©æ‰‹å·²å…³é—­ã€‚")
            break
        
        elif user_input in ["æœ¬ç§‘ç”Ÿ", "ç ”ç©¶ç”Ÿ"]:
            current_filter = user_input
            print(f"âœ… æœç´¢èŒƒå›´å·²åˆ‡æ¢ä¸ºï¼šã€{current_filter}ã€‘æ‰‹å†Œã€‚")
            continue
        
        if not user_input:
            continue

        print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
        
        result = rag_query(
            collection, 
            query=user_input, 
            handbook_type=current_filter
        )
        
        print("\n" + "--- æ™ºèƒ½åŠ©æ‰‹å›ç­” ---")
        print(result)
        print("----------------------")